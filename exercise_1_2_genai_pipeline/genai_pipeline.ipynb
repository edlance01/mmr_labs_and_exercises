{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE OVERVIEW\n",
    "\n",
    "In this exercise, we're going to provide an overview of a RAG pipeline.\n",
    "\n",
    "Prior to starting your will want to make sure your relational database tables AND your vector store tables have been created.  \n",
    "If you need to review them scripts they are:  \n",
    "    -*create_db_python.py*  \n",
    "    -*create_pg_vector_table.py*  \n",
    "\n",
    "[Click here to see lame_db schema](../static/images/mmr_db_schema.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps we're going to do in this exercise:  \n",
    "\n",
    "Step 1: Use python docx library to load our document (any .docx file).  \n",
    "Step 2: Chunking a document into paragraphs.  \n",
    "Step 3: (First time only) Check env variables and ensure relational AND vector store tables have been created.  \n",
    "Step 4: Connect to the database.  \n",
    "Step 5: Store our paragraph chunks in the relational table (text_chunks).  \n",
    "Step 6: After everything is stored as text in the database, we'll retrieve those paragraphs and embed/vectorize each one, storing it in the vector store (pgvector from Postgres in our case).  \n",
    "Note: Later we'll learn about summarizing and text splitting but for now, we're just focused on the flow / \"pipeline\".   \n",
    "Step 7: Next, we'll act as a user and send in a query, that will also be vectorized by the same tool we used to vectorize our paragraphs.  \n",
    "Step 8: Then we'll find and retrieve the vectors that are most similar to our query.    \n",
    "Step 9: Once we have the similar vectors, we'll submit them, along with the user query to our LLM and print our response.  \n",
    "     \n",
    "\n",
    "NOTE: When you setup directories for labs, you may have to run this code to add the virtual environment as a kernel (things work without this, but you get some warnings).  \n",
    "*python -m ipykernel install --user --name=myenv --display-name \"Python (myenv)\"*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Import docx library for Python and instantiate a document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document as DocxDocument\n",
    "file_path = \"Jupyter_Notebook_Info.docx\"\n",
    "doc = DocxDocument(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Extract and chunk into paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of document chunks is:45\n"
     ]
    }
   ],
   "source": [
    "doc_chunks = []\n",
    "for para in doc.paragraphs:\n",
    "            if para.text.strip():\n",
    "                doc_chunks.append(para.text)\n",
    "\n",
    "print(f\"The number of document chunks is:{len(doc_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 (First time only)\n",
    "\n",
    "You will want to make sure your env file has the proper database configuration info.\n",
    "\n",
    "If you have not yet ran *create_db_python.py*.  Take a minute to browse it and then run it please.\n",
    "This creates your relational database tables.\n",
    "\n",
    "The run *create_pgvector_table.py*.  This, creates the vector store table, mmr_vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 - Connect to the database using variables from .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "def get_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "                    dbname=os.getenv(\"dbname\"),\n",
    "                    user=os.getenv(\"dbuser\"),\n",
    "                    password=os.getenv(\"dbpassword\"),\n",
    "                    host=os.getenv(\"dbhost\"),\n",
    "                    port=os.getenv(\"dbport\"),\n",
    "                )\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        print(f\"Error: {error}\")\n",
    "    \n",
    "    return conn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - Store the chunks in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_id is:21\n"
     ]
    }
   ],
   "source": [
    "from psycopg2 import sql\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "\n",
    "    # parse file extension\n",
    "    file = Path(file_path).name\n",
    "    suffix = Path(file_path).suffix\n",
    "    file_ext = suffix.lstrip(\".\")\n",
    "\n",
    "    # read in the entire file contents so we can store them\n",
    "    with(open(file_path, \"rb\") as file_obj):\n",
    "        file_data = file_obj.read()\n",
    "\n",
    "    conn = get_connection()\n",
    "    with conn.cursor() as cursor:\n",
    "        # Insert file content into the complete_files table\n",
    "       \n",
    "        cursor.execute(\n",
    "                sql.SQL(\n",
    "                    \"INSERT INTO complete_files (file_name, file_data, file_ext) VALUES (%s, %s, %s) RETURNING pk\"\n",
    "                ),\n",
    "                [file, file_data, file_ext],\n",
    "            )\n",
    "            \n",
    "        file_id = cursor.fetchone()[0]  # Get the generated primary key (pk)\n",
    "        print(f\"file_id is:{file_id}\")\n",
    "\n",
    "        for chunk in doc_chunks:   \n",
    "            cursor.execute(\n",
    "                sql.SQL(\"INSERT INTO text_chunks (text, file_id) VALUES (%s, %s) RETURNING pk\"),\n",
    "                [chunk, file_id],\n",
    "            )\n",
    "    \n",
    "            conn.commit()  # Commit the transaction after each insert\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting file with chunks: {e}\")\n",
    "finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 - Vectorization  (Note: can take ~30-45 seconds to run to completion)\n",
    "A. Retrieve Current Chunks from Database.  \n",
    "B. Create embedding of each chunk.  \n",
    "C. Store vector of embedding in pgvector (vector store).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Retreive Currrent Chunks from Database\n",
    "current_chunks = []\n",
    "conn = get_connection()\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\n",
    "        sql.SQL(\"SELECT pk, text FROM text_chunks WHERE is_vectorized = FALSE\"),\n",
    "    )\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"len of rows:{len(rows)}\")\n",
    "    for row in rows:\n",
    "         current_chunks.append(row) # append tuple of pk, text, file_id\n",
    "    #     cursor.execute(f\"UPDATE text_chunks SET is_vectorized = TRUE WHERE pk = %s\",\n",
    "    #                    (row[0],))\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "# Get the embedding model\n",
    "openai_embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=openai_key)\n",
    "   \n",
    "vector_dict = {}\n",
    "for chunk in current_chunks:\n",
    "     content = openai_embedding.embed_query(chunk[1])\n",
    "     # Convert the embedding values to floats (ensures compatibility with storage formats)\n",
    "     float_content = [float(x) for x in content]\n",
    "     vector_dict[chunk[0]] = float_content\n",
    "\n",
    "\n",
    "# # add the vectorized content to the vector store\n",
    "with conn.cursor() as cursor:\n",
    "    chunk_type = \"text\"  # Only working with text right now, so hard-coding chunk_type = \"text\"\n",
    "    \n",
    "    for cid, vec in vector_dict.items():\n",
    "        cursor.execute(\n",
    "            sql.SQL(\"INSERT INTO mmr_vector (vector, chunk_type, chunk_id) VALUES (%s, %s, %s)\"),\n",
    "            [vec, chunk_type, cid]\n",
    "        )\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7 - Vectorize Incoming Query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"Where should I point my web browser after Jupyter is running?\"\n",
    "# query = \"What is the command to install jupyter?\"\n",
    "# query = \"You can execute a cell by clicking on it and pressing what?\"\n",
    "# query = \"What City and State had the highest temperature?\"\n",
    "\n",
    "vectorized_query = openai_embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8 - Find Similar Vectors\n",
    "\n",
    "pgvector similarity search operators:  \n",
    "<->:\n",
    "Represents the Euclidean distance between two vectors, which is the \"straight-line\" distance between them in multi-dimensional space.  \n",
    "<=>:\n",
    "Calculates the cosine similarity between vectors, which is often preferred for high-dimensional data as it focuses on the angle between vectors rather than their magnitude.  \n",
    "<#>\n",
    ": Computes the inner product of two vectors, where each corresponding element is multiplied and summed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_k = 3 # only bring back the top 3 results\n",
    "conn = get_connection()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\n",
    "        sql.SQL(\n",
    "            \"\"\"SELECT pk, chunk_type, chunk_id, 1 - (vector <=> %s::VECTOR) AS similarity\n",
    "               FROM mmr_vector\n",
    "               ORDER BY similarity DESC\n",
    "               LIMIT %s\"\"\"\n",
    "        ),\n",
    "        [vectorized_query, top_k],\n",
    "    )\n",
    "    rows = cur.fetchall()\n",
    "    similar_chunk_ids = []\n",
    "    if rows:\n",
    "        for row in rows:\n",
    "            similar_chunk_ids.append(row[2])\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9 - Get the text chunks of the closest matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar_chunk_ids:[303, 303, 304]\n"
     ]
    }
   ],
   "source": [
    "conn = get_connection()\n",
    "with conn.cursor() as cur:\n",
    "    print(f\"similar_chunk_ids:{similar_chunk_ids}\")\n",
    "    similar_context = []\n",
    "    for chunk_id in similar_chunk_ids:\n",
    "        cur.execute(\n",
    "            sql.SQL(\"\"\"SELECT text FROM text_chunks where pk = %s\"\"\"),\n",
    "            [chunk_id],\n",
    "        )\n",
    "        row = cur.fetchone()  # Fetch only one row for the current chunk_id\n",
    "        similar_context.append(row[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10 - Retrieval  \n",
    "Submit Similar Vectors to LLM with query to retrieve a response.\n",
    "\n",
    "Note the prompt structure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CONTEXT ITEM:Jupyter Notebook Setup'\n",
      "'CONTEXT ITEM:Jupyter Notebook Setup'\n",
      "('CONTEXT ITEM:Once Jupyter is running, point your web browser at '\n",
      " 'http://localhost:8888 to start using Jupyter notebooks. If everything worked '\n",
      " 'correctly, you should see a screen like this, showing all available Jupyter '\n",
      " 'notebooks in the current directory:')\n",
      "\n",
      "\n",
      "\n",
      "('RESPONSE:The retrieved context does not provide information on the command '\n",
      " 'to install Jupyter.')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "# Show the similar content retrieved\n",
    "for sc in similar_context:\n",
    "    pprint(f\"CONTEXT ITEM:{sc}\")\n",
    "\n",
    "# Format the prompt\n",
    "prompt = f\"\"\"You are an assistant for question-answering tasks. Use only \n",
    "the following pieces of retrieved context to answer the \n",
    "question. Use 3 sentences maximum to keep your answer concise. Here's a query: \n",
    "{query} and here are similar queries of retrieved context: {similar_context}. Again,\n",
    "only base your answer on the similar queries data within the similar context.\"\"\"\n",
    "\n",
    "# Call the OpenAI ChatCompletion API using the updated method\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Extract and print the response\n",
    "print(\"\\n\\n\")\n",
    "pprint(f\"RESPONSE:{response.choices[0].message.content.strip()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
